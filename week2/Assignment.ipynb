{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7a3dc4-75db-411e-a3dc-ea07255d5860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.5.1\n"
     ]
    }
   ],
   "source": [
    "import pyspark \n",
    "print(pyspark.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a219c0c-767f-4d8f-a7b6-cdb3141330a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"python\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"python\"\n",
    "os.environ[\"spark.python.worker.reuse\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07398503-9d69-4eda-8296-dc295a26a153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b395b1b-690b-4c4f-ab26-81836e9ee089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create SparkSession\n",
    "spark = SparkSession.builder.appName(\"EmployeeDataProcessing\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5404dad-5474-4095-bec4-efc02c854fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000002117A808C10>\n"
     ]
    }
   ],
   "source": [
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db6eca89-951a-4c06-931e-b9c7df6a1aa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[employee_id: int, name: string, department: string, salary: int, joining_year: int, bonus_percent: int]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Load employee.csv into DataFrame\n",
    "employee_df = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(\"Dataset/employees.csv\")\n",
    "employee_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb0d0f56-cb47-472f-a005-d26b1edcfe33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------+------+------------+-------------+\n",
      "|employee_id|   name|department|salary|joining_year|bonus_percent|\n",
      "+-----------+-------+----------+------+------------+-------------+\n",
      "|        101|  Alice|        HR| 50000|        2018|            5|\n",
      "|        102|    Bob|   Finance| 60000|        2019|            7|\n",
      "|        103|Charlie|        IT| 75000|        2017|           10|\n",
      "|        104|  David|   Finance| 62000|        2020|            6|\n",
      "|        105|    Eva|        IT| 80000|        2021|           12|\n",
      "|        106|  Frank|        HR| 52000|        2018|            5|\n",
      "|        107|  Grace|        IT| 90000|        2019|           15|\n",
      "+-----------+-------+----------+------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Shows the employee DataFrame in tabular format\n",
    "employee_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "223ca95e-6503-4d71-a8a7-c50778001999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+\n",
      "|   name|salary|\n",
      "+-------+------+\n",
      "|  Alice| 50000|\n",
      "|    Bob| 60000|\n",
      "|Charlie| 75000|\n",
      "|  David| 62000|\n",
      "|    Eva| 80000|\n",
      "|  Frank| 52000|\n",
      "|  Grace| 90000|\n",
      "+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Select only name and salary columns\n",
    "selected_df = employee_df.select(\"name\", \"salary\")\n",
    "selected_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ff9d89f-4395-4fc7-89f9-9f966dc3c7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------+------+------------+-------------+\n",
      "|employee_id|   name|department|salary|joining_year|bonus_percent|\n",
      "+-----------+-------+----------+------+------------+-------------+\n",
      "|        103|Charlie|        IT| 75000|        2017|           10|\n",
      "|        104|  David|   Finance| 62000|        2020|            6|\n",
      "|        105|    Eva|        IT| 80000|        2021|           12|\n",
      "|        107|  Grace|        IT| 90000|        2019|           15|\n",
      "+-----------+-------+----------+------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Filter employees with salary > 60000\n",
    "from pyspark.sql.functions import col, expr, avg, count, max \n",
    "salAbove60k_df = employee_df.filter(col(\"salary\") > 60000)\n",
    "salAbove60k_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "759962aa-4302-487c-bdc4-f3a9a5fd50c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------+------+------------+-------------+------------+\n",
      "|employee_id|   name|department|salary|joining_year|bonus_percent|bonus_amount|\n",
      "+-----------+-------+----------+------+------------+-------------+------------+\n",
      "|        101|  Alice|        HR| 50000|        2018|            5|      2500.0|\n",
      "|        102|    Bob|   Finance| 60000|        2019|            7|      4200.0|\n",
      "|        103|Charlie|        IT| 75000|        2017|           10|      7500.0|\n",
      "|        104|  David|   Finance| 62000|        2020|            6|      3720.0|\n",
      "|        105|    Eva|        IT| 80000|        2021|           12|      9600.0|\n",
      "|        106|  Frank|        HR| 52000|        2018|            5|      2600.0|\n",
      "|        107|  Grace|        IT| 90000|        2019|           15|     13500.0|\n",
      "+-----------+-------+----------+------+------------+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Add bonus_amount = salary * bonus_percent / 100\n",
    "employee_df = employee_df.withColumn(\"bonus_amount\", expr(\"salary * (bonus_percent / 100)\"))\n",
    "employee_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "039dc5fe-5eac-47e0-83e7-7eda4cb0c3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------+------+-----------+-------------+------------+\n",
      "|employee_id|   name|department|salary|year_joined|bonus_percent|bonus_amount|\n",
      "+-----------+-------+----------+------+-----------+-------------+------------+\n",
      "|        101|  Alice|        HR| 50000|       2018|            5|      2500.0|\n",
      "|        102|    Bob|   Finance| 60000|       2019|            7|      4200.0|\n",
      "|        103|Charlie|        IT| 75000|       2017|           10|      7500.0|\n",
      "|        104|  David|   Finance| 62000|       2020|            6|      3720.0|\n",
      "|        105|    Eva|        IT| 80000|       2021|           12|      9600.0|\n",
      "|        106|  Frank|        HR| 52000|       2018|            5|      2600.0|\n",
      "|        107|  Grace|        IT| 90000|       2019|           15|     13500.0|\n",
      "+-----------+-------+----------+------+-----------+-------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Rename joining_year to year_joined\n",
    "employee_df = employee_df.withColumnRenamed(\"joining_year\", \"year_joined\")\n",
    "employee_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7748cb4d-301c-4455-85b2-fb3efa094712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------+------+-----------+------------+\n",
      "|employee_id|   name|department|salary|year_joined|bonus_amount|\n",
      "+-----------+-------+----------+------+-----------+------------+\n",
      "|        101|  Alice|        HR| 50000|       2018|      2500.0|\n",
      "|        102|    Bob|   Finance| 60000|       2019|      4200.0|\n",
      "|        103|Charlie|        IT| 75000|       2017|      7500.0|\n",
      "|        104|  David|   Finance| 62000|       2020|      3720.0|\n",
      "|        105|    Eva|        IT| 80000|       2021|      9600.0|\n",
      "|        106|  Frank|        HR| 52000|       2018|      2600.0|\n",
      "|        107|  Grace|        IT| 90000|       2019|     13500.0|\n",
      "+-----------+-------+----------+------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Drop bonus_percent column\n",
    "employee_df = employee_df.drop(\"bonus_percent\")\n",
    "employee_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2fe29cd0-1475-4e89-995f-33545942338a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|department|       avg_salary|\n",
      "+----------+-----------------+\n",
      "|        HR|          51000.0|\n",
      "|   Finance|          61000.0|\n",
      "|        IT|81666.66666666667|\n",
      "+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Find average salary per department\n",
    "avg_salary_data = employee_df.groupBy(\"department\").agg(avg(\"salary\").alias(\"avg_salary\"))\n",
    "avg_salary_data.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76f766ec-a7b0-4524-9eaa-30b28fde7bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+\n",
      "|department|employee_count|\n",
      "+----------+--------------+\n",
      "|        HR|             2|\n",
      "|   Finance|             2|\n",
      "|        IT|             3|\n",
      "+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Count number of employees per department\n",
    "emp_cnt_df = employee_df.groupBy(\"department\").agg(count(\"*\").alias(\"employee_count\"))\n",
    "emp_cnt_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "212e820f-02cf-4186-9fdf-372a9cf4f77e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Find max salary in the dataset\n",
    "max_salary = employee_df.agg({\"salary\": \"max\"}).collect()[0][0]\n",
    "print(max_salary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ea7e14e-8bdf-4ae3-99cf-e75254afd360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------+------+-----------+------------+\n",
      "|employee_id|   name|department|salary|year_joined|bonus_amount|\n",
      "+-----------+-------+----------+------+-----------+------------+\n",
      "|        107|  Grace|        IT| 90000|       2019|     13500.0|\n",
      "|        105|    Eva|        IT| 80000|       2021|      9600.0|\n",
      "|        103|Charlie|        IT| 75000|       2017|      7500.0|\n",
      "|        104|  David|   Finance| 62000|       2020|      3720.0|\n",
      "|        102|    Bob|   Finance| 60000|       2019|      4200.0|\n",
      "|        106|  Frank|        HR| 52000|       2018|      2600.0|\n",
      "|        101|  Alice|        HR| 50000|       2018|      2500.0|\n",
      "+-----------+-------+----------+------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Sort employees by salary descending\n",
    "sorted_salary = employee_df.orderBy(col(\"salary\").desc())\n",
    "sorted_salary.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b654628f-3c27-48c5-9818-dcec95355e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------+------+-----------+------------+\n",
      "|employee_id|   name|department|salary|year_joined|bonus_amount|\n",
      "+-----------+-------+----------+------+-----------+------------+\n",
      "|        103|Charlie|        IT| 75000|       2017|      7500.0|\n",
      "|        101|  Alice|        HR| 50000|       2018|      2500.0|\n",
      "|        106|  Frank|        HR| 52000|       2018|      2600.0|\n",
      "|        102|    Bob|   Finance| 60000|       2019|      4200.0|\n",
      "|        107|  Grace|        IT| 90000|       2019|     13500.0|\n",
      "|        104|  David|   Finance| 62000|       2020|      3720.0|\n",
      "|        105|    Eva|        IT| 80000|       2021|      9600.0|\n",
      "+-----------+-------+----------+------+-----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 12: Sort employees by joining year ascending\n",
    "sorted_by_joining_yr = employee_df.orderBy(col(\"year_joined\").asc())\n",
    "sorted_by_joining_yr.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "549db0dd-7a52-4e5f-acfb-26a4c8a5e2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+\n",
      "|department|     location|\n",
      "+----------+-------------+\n",
      "|        HR|     New York|\n",
      "|        IT|San Francisco|\n",
      "|   Finance|      Chicago|\n",
      "+----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 13: Create department DataFrame with dept_name and location only\n",
    "department_data = [(\"HR\", \"New York\"), (\"IT\", \"San Francisco\"), (\"Finance\", \"Chicago\")]\n",
    "dept_columns = [\"department\", \"location\"]\n",
    "dept_df = spark.createDataFrame(department_data, dept_columns)\n",
    "dept_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1532a14-142c-471c-8990-1cb257a20c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+-------+------+-----------+------------+-------------+\n",
      "|department|employee_id|   name|salary|year_joined|bonus_amount|     location|\n",
      "+----------+-----------+-------+------+-----------+------------+-------------+\n",
      "|        HR|        106|  Frank| 52000|       2018|      2600.0|     New York|\n",
      "|        HR|        101|  Alice| 50000|       2018|      2500.0|     New York|\n",
      "|        IT|        107|  Grace| 90000|       2019|     13500.0|San Francisco|\n",
      "|        IT|        105|    Eva| 80000|       2021|      9600.0|San Francisco|\n",
      "|        IT|        103|Charlie| 75000|       2017|      7500.0|San Francisco|\n",
      "|   Finance|        104|  David| 62000|       2020|      3720.0|      Chicago|\n",
      "|   Finance|        102|    Bob| 60000|       2019|      4200.0|      Chicago|\n",
      "+----------+-----------+-------+------+-----------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 14: Join with employee_df on 'department'\n",
    "joined_df = employee_df.join(dept_df, on=\"department\", how=\"inner\")\n",
    "joined_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2883bb01-0575-4690-bbef-5906c04b2c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Employees: 7\n"
     ]
    }
   ],
   "source": [
    "# Step 15: Total number of employees\n",
    "total_employees = employee_df.count()\n",
    "print(\"Total Employees:\", total_employees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38153ee1-fe9f-4677-81a7-a27b17811322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected Rows: [Row(employee_id=101, name='Alice', department='HR', salary=50000, year_joined=2018, bonus_amount=2500.0), Row(employee_id=102, name='Bob', department='Finance', salary=60000, year_joined=2019, bonus_amount=4200.0), Row(employee_id=103, name='Charlie', department='IT', salary=75000, year_joined=2017, bonus_amount=7500.0), Row(employee_id=104, name='David', department='Finance', salary=62000, year_joined=2020, bonus_amount=3720.0), Row(employee_id=105, name='Eva', department='IT', salary=80000, year_joined=2021, bonus_amount=9600.0), Row(employee_id=106, name='Frank', department='HR', salary=52000, year_joined=2018, bonus_amount=2600.0), Row(employee_id=107, name='Grace', department='IT', salary=90000, year_joined=2019, bonus_amount=13500.0)]\n"
     ]
    }
   ],
   "source": [
    "# Step 17: Collect all rows into Python objects\n",
    "all_rows = employee_df.collect()\n",
    "print(\"Collected Rows:\", all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f576e3bf-5c07-4d28-bb5f-63c8ca817a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 3 Employees: [Row(employee_id=101, name='Alice', department='HR', salary=50000, year_joined=2018, bonus_amount=2500.0), Row(employee_id=102, name='Bob', department='Finance', salary=60000, year_joined=2019, bonus_amount=4200.0), Row(employee_id=103, name='Charlie', department='IT', salary=75000, year_joined=2017, bonus_amount=7500.0)]\n"
     ]
    }
   ],
   "source": [
    "# Step 18: Take first 3 employees\n",
    "first_three = employee_df.take(3)\n",
    "print(\"First 3 Employees:\", first_three)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
